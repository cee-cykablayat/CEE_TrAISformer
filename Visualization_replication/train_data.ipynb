{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09081b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da4d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fb08dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (250, 2)\n",
      "┌───────────┬─────────────────────────────────┐\n",
      "│ mmsi      ┆ traj                            │\n",
      "│ ---       ┆ ---                             │\n",
      "│ i64       ┆ list[array[f64, 6]]             │\n",
      "╞═══════════╪═════════════════════════════════╡\n",
      "│ 205451000 ┆ [[0.902285, 0.000241, … 2.0545… │\n",
      "│ 205451000 ┆ [[0.871675, 0.558683, … 2.0545… │\n",
      "│ 209114000 ┆ [[0.25416, 0.498695, … 2.09114… │\n",
      "│ 209114000 ┆ [[0.25783, 0.000157, … 2.09114… │\n",
      "│ 209114000 ┆ [[0.272522, 0.668102, … 2.0911… │\n",
      "│ …         ┆ …                               │\n",
      "│ 220609000 ┆ [[0.883933, 0.124074, … 2.2060… │\n",
      "│ 220609000 ┆ [[0.837533, 0.518766, … 2.2060… │\n",
      "│ 220609000 ┆ [[0.8628, 0.142284, … 2.20609e… │\n",
      "│ 220609000 ┆ [[0.8386, 0.51037, … 2.20609e8… │\n",
      "│ 220609000 ┆ [[0.871667, 0.558766, … 2.2060… │\n",
      "└───────────┴─────────────────────────────────┘\n",
      "(10605, 2)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import polars as pl\n",
    "\n",
    "# Path to the pickle file\n",
    "train_path = \"/home/crimsondeepdarshak/Desktop/Deep_Darshak/References/TRAIS_former_paper_Work_/CEE_TrAISformer-1/data/ct_dma/ct_dma_train.pkl\"\n",
    "\n",
    "# Load the raw Python object from pickle\n",
    "with open(train_path, \"rb\") as f:\n",
    "    raw_data = pickle.load(f)\n",
    "\n",
    "# Convert to a Polars DataFrame\n",
    "train_df = pl.DataFrame(raw_data)\n",
    "\n",
    "# Show the first 25 rows\n",
    "print(train_df.head(250))\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35063307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (250, 2)\n",
      "┌───────────┬─────────────────────────────────┐\n",
      "│ mmsi      ┆ traj                            │\n",
      "│ ---       ┆ ---                             │\n",
      "│ i64       ┆ list[array[f64, 6]]             │\n",
      "╞═══════════╪═════════════════════════════════╡\n",
      "│ 205685000 ┆ [[0.94206, 0.000056, … 2.05685… │\n",
      "│ 209155000 ┆ [[0.000084, 0.21846, … 2.09155… │\n",
      "│ 209155000 ┆ [[0.453855, 0.931141, … 2.0915… │\n",
      "│ 209294000 ┆ [[0.918573, 0.00024, … 2.09294… │\n",
      "│ 209336000 ┆ [[0.00007, 0.896099, … 2.09336… │\n",
      "│ …         ┆ …                               │\n",
      "│ 265191000 ┆ [[0.588822, 0.014851, … 2.6519… │\n",
      "│ 265191000 ┆ [[0.074312, 0.000251, … 2.6519… │\n",
      "│ 265191000 ┆ [[0.588804, 0.014849, … 2.6519… │\n",
      "│ 265191000 ┆ [[0.891112, 0.000024, … 2.6519… │\n",
      "│ 265412000 ┆ [[0.840753, 0.291487, … 2.6541… │\n",
      "└───────────┴─────────────────────────────────┘\n",
      "(1481, 2)\n"
     ]
    }
   ],
   "source": [
    "val_path = \"/home/crimsondeepdarshak/Desktop/Deep_Darshak/References/TRAIS_former_paper_Work_/CEE_TrAISformer-1/data/ct_dma/ct_dma_valid.pkl\"\n",
    "\n",
    "with open(val_path, \"rb\") as f:\n",
    "    raw_data = pickle.load(f)\n",
    "\n",
    "# Convert to a Polars DataFrame\n",
    "val_df = pl.DataFrame(raw_data)\n",
    "print(val_df.head(250))\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad72d722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (250, 2)\n",
      "┌───────────┬─────────────────────────────────┐\n",
      "│ mmsi      ┆ traj                            │\n",
      "│ ---       ┆ ---                             │\n",
      "│ i64       ┆ list[array[f64, 6]]             │\n",
      "╞═══════════╪═════════════════════════════════╡\n",
      "│ 209155000 ┆ [[0.086491, 0.863617, … 2.0915… │\n",
      "│ 209332000 ┆ [[0.453851, 0.931113, … 2.0933… │\n",
      "│ 209332000 ┆ [[0.00006, 0.836544, … 2.09332… │\n",
      "│ 209332000 ┆ [[0.366254, 0.245355, … 2.0933… │\n",
      "│ 209468000 ┆ [[0.88554, 0.000019, … 2.09468… │\n",
      "│ …         ┆ …                               │\n",
      "│ 265882000 ┆ [[0.543773, 0.268277, … 2.6588… │\n",
      "│ 265882000 ┆ [[0.058905, 0.999996, … 2.6588… │\n",
      "│ 265882000 ┆ [[0.878487, 0.13486, … 2.65882… │\n",
      "│ 265882000 ┆ [[0.083647, 0.865604, … 2.6588… │\n",
      "│ 265882000 ┆ [[0.876678, 0.107879, … 2.6588… │\n",
      "└───────────┴─────────────────────────────────┘\n",
      "(1593, 2)\n"
     ]
    }
   ],
   "source": [
    "val_path = \"/home/crimsondeepdarshak/Desktop/Deep_Darshak/References/TRAIS_former_paper_Work_/CEE_TrAISformer-1/data/ct_dma/ct_dma_test.pkl\"\n",
    "\n",
    "with open(val_path, \"rb\") as f:\n",
    "    raw_data = pickle.load(f)\n",
    "\n",
    "# Convert to a Polars DataFrame\n",
    "test_df = pl.DataFrame(raw_data)\n",
    "print(test_df.head(250))\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77eab625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (48676109, 16)\n",
      "\n",
      "Column names: ['MMSI', 'BASEDATETIME', 'LAT', 'LON', 'SOG', 'COG', 'HEADING', 'NAVSTATUS', 'VESSELTYPE', 'HOUR', 'DAY', 'WEEKDAY', 'MONTH', 'WEEK', 'SPEED_CATEGORY', 'DATE']\n",
      "\n",
      "Data types:\n",
      "[Int64, Datetime(time_unit='us', time_zone=None), Float32, Float32, Float32, Float32, Int64, Int64, Int64, Int8, Int8, Int8, Int8, Int8, String, Date]\n",
      "\n",
      "================================================================================\n",
      "25 Random Samples:\n",
      "================================================================================\n",
      "shape: (50, 16)\n",
      "┌───────────┬──────────────┬───────────┬─────────────┬───┬───────┬──────┬─────────────┬────────────┐\n",
      "│ MMSI      ┆ BASEDATETIME ┆ LAT       ┆ LON         ┆ … ┆ MONTH ┆ WEEK ┆ SPEED_CATEG ┆ DATE       │\n",
      "│ ---       ┆ ---          ┆ ---       ┆ ---         ┆   ┆ ---   ┆ ---  ┆ ORY         ┆ ---        │\n",
      "│ i64       ┆ datetime[μs] ┆ f32       ┆ f32         ┆   ┆ i8    ┆ i8   ┆ ---         ┆ date       │\n",
      "│           ┆              ┆           ┆             ┆   ┆       ┆      ┆ str         ┆            │\n",
      "╞═══════════╪══════════════╪═══════════╪═════════════╪═══╪═══════╪══════╪═════════════╪════════════╡\n",
      "│ 367330820 ┆ 2025-01-10   ┆ 29.35689  ┆ -90.250618  ┆ … ┆ 1     ┆ 2    ┆ Slow        ┆ 2025-01-10 │\n",
      "│           ┆ 08:22:01     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ 367378120 ┆ 2025-01-04   ┆ 30.42996  ┆ -91.201218  ┆ … ┆ 1     ┆ 1    ┆ Stationary  ┆ 2025-01-04 │\n",
      "│           ┆ 05:21:43     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ 303589000 ┆ 2025-01-05   ┆ 29.341061 ┆ -94.745773  ┆ … ┆ 1     ┆ 1    ┆ Medium      ┆ 2025-01-05 │\n",
      "│           ┆ 00:08:21     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ 368141960 ┆ 2025-01-07   ┆ 29.78335  ┆ -95.09671   ┆ … ┆ 1     ┆ 2    ┆ Stationary  ┆ 2025-01-07 │\n",
      "│           ┆ 22:15:43     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ 367483260 ┆ 2025-01-05   ┆ 29.04904  ┆ -90.178452  ┆ … ┆ 1     ┆ 1    ┆ Slow        ┆ 2025-01-05 │\n",
      "│           ┆ 14:17:51     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ …         ┆ …            ┆ …         ┆ …           ┆ … ┆ …     ┆ …    ┆ …           ┆ …          │\n",
      "│ 366345000 ┆ 2025-01-10   ┆ 13.46109  ┆ 144.666046  ┆ … ┆ 1     ┆ 2    ┆ Stationary  ┆ 2025-01-10 │\n",
      "│           ┆ 17:17:08     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ 316001262 ┆ 2025-01-06   ┆ 49.432461 ┆ -123.472191 ┆ … ┆ 1     ┆ 2    ┆ Stationary  ┆ 2025-01-06 │\n",
      "│           ┆ 01:57:59     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ 367310330 ┆ 2025-01-04   ┆ 29.42201  ┆ -92.538239  ┆ … ┆ 1     ┆ 1    ┆ Medium      ┆ 2025-01-04 │\n",
      "│           ┆ 00:59:15     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ 367393830 ┆ 2025-01-09   ┆ 41.16061  ┆ -72.844139  ┆ … ┆ 1     ┆ 2    ┆ Slow        ┆ 2025-01-09 │\n",
      "│           ┆ 13:39:23     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "│ 368006130 ┆ 2025-01-07   ┆ 34.405819 ┆ -119.690872 ┆ … ┆ 1     ┆ 2    ┆ Stationary  ┆ 2025-01-07 │\n",
      "│           ┆ 14:57:43     ┆           ┆             ┆   ┆       ┆      ┆             ┆            │\n",
      "└───────────┴──────────────┴───────────┴─────────────┴───┴───────┴──────┴─────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Path to the parquet file\n",
    "parquet_path = \"/home/crimsondeepdarshak/Desktop/Deep_Darshak/AIS_data_demo/processed/10_Day_US.parquet\"\n",
    "\n",
    "# Load the parquet file using Polars\n",
    "ais_df = pl.read_parquet(parquet_path)\n",
    "\n",
    "# Show basic info about the dataset\n",
    "print(f\"Dataset shape: {ais_df.shape}\")\n",
    "print(f\"\\nColumn names: {ais_df.columns}\")\n",
    "print(f\"\\nData types:\\n{ais_df.dtypes}\")\n",
    "\n",
    "# Show 25 random samples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"25 Random Samples:\")\n",
    "print(\"=\"*80)\n",
    "random_samples = ais_df.sample(n=50, seed=42)\n",
    "print(random_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f8c2dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parquet file...\n",
      "Original data shape: (48676109, 6)\n",
      "Number of unique vessels (MMSI): 22962\n",
      "\n",
      "Interpolating data for each vessel...\n",
      "This may take a while for large datasets...\n",
      "Processing 22962 vessels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56123/607136323.py:83: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  chunk_df = df.filter(pl.col(\"MMSI\").is_in(chunk_mmsis))\n",
      "/tmp/ipykernel_56123/607136323.py:62: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_pd = merged_pd.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5000/22962 vessels...\n",
      "Processed 10000/22962 vessels...\n",
      "Processed 15000/22962 vessels...\n",
      "Processed 20000/22962 vessels...\n",
      "Processed 22962/22962 vessels...\n",
      "\n",
      "Combining interpolated data...\n",
      "\n",
      "Interpolated data shape: (12147218, 6)\n",
      "Number of unique vessels: 22962\n",
      "\n",
      "Sample of interpolated data:\n",
      "shape: (10, 6)\n",
      "┌─────────────────────┬───────────┬──────────┬────────────┬─────┬────────────┐\n",
      "│ BASEDATETIME        ┆ MMSI      ┆ LAT      ┆ LON        ┆ SOG ┆ COG        │\n",
      "│ ---                 ┆ ---       ┆ ---      ┆ ---        ┆ --- ┆ ---        │\n",
      "│ datetime[μs]        ┆ i64       ┆ f32      ┆ f32        ┆ f32 ┆ f32        │\n",
      "╞═════════════════════╪═══════════╪══════════╪════════════╪═════╪════════════╡\n",
      "│ 2025-01-02 00:43:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 00:58:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 01:13:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 01:28:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 01:43:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 01:58:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 02:13:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 02:28:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 02:43:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "│ 2025-01-02 02:58:44 ┆ 103669999 ┆ 30.36442 ┆ -89.087021 ┆ 0.0 ┆ 145.600006 │\n",
      "└─────────────────────┴───────────┴──────────┴────────────┴─────┴────────────┘\n",
      "\n",
      "Time range per vessel (sample of 5 vessels):\n",
      "  MMSI 103669999: 862 points, duration: 8 days, 23:15:00\n",
      "  MMSI 111826088: 1 points, duration: 0:00:00\n",
      "  MMSI 112119600: 279 points, duration: 2 days, 21:30:00\n",
      "  MMSI 113222332: 1 points, duration: 0:00:00\n",
      "  MMSI 123456789: 696 points, duration: 7 days, 5:45:00\n",
      "\n",
      "Saving interpolated data to: /home/crimsondeepdarshak/Desktop/Deep_Darshak/AIS_data_demo/processed/10_Day_US_interpolated_15min.parquet\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the parquet file\n",
    "parquet_path = \"/home/crimsondeepdarshak/Desktop/Deep_Darshak/AIS_data_demo/processed/10_Day_US.parquet\"\n",
    "\n",
    "# Load the parquet file\n",
    "print(\"Loading parquet file...\")\n",
    "ais_df = pl.read_parquet(parquet_path)\n",
    "\n",
    "# Select only the columns we need for interpolation\n",
    "df = ais_df.select([\"MMSI\", \"BASEDATETIME\", \"LAT\", \"LON\", \"SOG\", \"COG\"])\n",
    "\n",
    "# Sort by MMSI and BASEDATETIME\n",
    "df = df.sort([\"MMSI\", \"BASEDATETIME\"])\n",
    "\n",
    "print(f\"Original data shape: {df.shape}\")\n",
    "print(f\"Number of unique vessels (MMSI): {df['MMSI'].n_unique()}\")\n",
    "\n",
    "# Function to interpolate for a single vessel\n",
    "def interpolate_vessel(group):\n",
    "    \"\"\"Interpolate LAT, LON, SOG, COG at 15-minute intervals for a vessel\"\"\"\n",
    "    mmsi = group[\"MMSI\"][0]\n",
    "    \n",
    "    # Get time range\n",
    "    min_time = group[\"BASEDATETIME\"].min()\n",
    "    max_time = group[\"BASEDATETIME\"].max()\n",
    "    \n",
    "    # Create 15-minute interval time series\n",
    "    time_intervals = []\n",
    "    current_time = min_time\n",
    "    while current_time <= max_time:\n",
    "        time_intervals.append(current_time)\n",
    "        current_time = current_time + timedelta(minutes=15)\n",
    "    \n",
    "    if len(time_intervals) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Create a DataFrame with the time intervals\n",
    "    intervals_df = pl.DataFrame({\n",
    "        \"BASEDATETIME\": time_intervals,\n",
    "        \"MMSI\": [mmsi] * len(time_intervals)\n",
    "    })\n",
    "    \n",
    "    # Merge with original data to get existing points\n",
    "    merged = intervals_df.join(\n",
    "        group.select([\"BASEDATETIME\", \"LAT\", \"LON\", \"SOG\", \"COG\"]),\n",
    "        on=\"BASEDATETIME\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Convert to pandas for interpolation (Polars doesn't have built-in interpolation)\n",
    "    merged_pd = merged.to_pandas()\n",
    "    merged_pd = merged_pd.sort_values(\"BASEDATETIME\")\n",
    "    \n",
    "    # Interpolate each column using linear interpolation\n",
    "    for col in [\"LAT\", \"LON\", \"SOG\", \"COG\"]:\n",
    "        merged_pd[col] = merged_pd[col].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "    \n",
    "    # Handle any remaining NaN values (forward fill, then backward fill)\n",
    "    merged_pd = merged_pd.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    \n",
    "    # Convert back to Polars\n",
    "    result = pl.from_pandas(merged_pd)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Process each vessel using group_by for efficiency\n",
    "print(\"\\nInterpolating data for each vessel...\")\n",
    "print(\"This may take a while for large datasets...\")\n",
    "\n",
    "# Get unique MMSIs and process in chunks\n",
    "unique_mmsis = df[\"MMSI\"].unique().sort()\n",
    "total_vessels = len(unique_mmsis)\n",
    "print(f\"Processing {total_vessels} vessels...\")\n",
    "\n",
    "interpolated_dfs = []\n",
    "chunk_size = 1000  # Process 1000 vessels at a time\n",
    "\n",
    "for i in range(0, total_vessels, chunk_size):\n",
    "    chunk_mmsis = unique_mmsis[i:i+chunk_size]\n",
    "    chunk_df = df.filter(pl.col(\"MMSI\").is_in(chunk_mmsis))\n",
    "    \n",
    "    # Process each vessel in the chunk\n",
    "    chunk_results = []\n",
    "    for mmsi in chunk_mmsis:\n",
    "        vessel_data = chunk_df.filter(pl.col(\"MMSI\") == mmsi)\n",
    "        if len(vessel_data) > 0:\n",
    "            interpolated = interpolate_vessel(vessel_data)\n",
    "            if interpolated is not None:\n",
    "                chunk_results.append(interpolated)\n",
    "    \n",
    "    if chunk_results:\n",
    "        interpolated_dfs.extend(chunk_results)\n",
    "    \n",
    "    # Progress update\n",
    "    if (i + chunk_size) % 5000 == 0 or (i + chunk_size) >= total_vessels:\n",
    "        print(f\"Processed {min(i + chunk_size, total_vessels)}/{total_vessels} vessels...\")\n",
    "\n",
    "# Combine all interpolated data\n",
    "print(\"\\nCombining interpolated data...\")\n",
    "if interpolated_dfs:\n",
    "    interpolated_df = pl.concat(interpolated_dfs)\n",
    "    \n",
    "    # Sort by MMSI and BASEDATETIME\n",
    "    interpolated_df = interpolated_df.sort([\"MMSI\", \"BASEDATETIME\"])\n",
    "    \n",
    "    print(f\"\\nInterpolated data shape: {interpolated_df.shape}\")\n",
    "    print(f\"Number of unique vessels: {interpolated_df['MMSI'].n_unique()}\")\n",
    "    \n",
    "    # Show sample of interpolated data\n",
    "    print(\"\\nSample of interpolated data:\")\n",
    "    print(interpolated_df.head(10))\n",
    "    \n",
    "    # Show statistics\n",
    "    print(\"\\nTime range per vessel (sample of 5 vessels):\")\n",
    "    sample_mmsis = interpolated_df[\"MMSI\"].unique()[:5]\n",
    "    for mmsi in sample_mmsis:\n",
    "        vessel_data = interpolated_df.filter(pl.col(\"MMSI\") == mmsi)\n",
    "        time_range = vessel_data[\"BASEDATETIME\"].max() - vessel_data[\"BASEDATETIME\"].min()\n",
    "        num_points = len(vessel_data)\n",
    "        print(f\"  MMSI {mmsi}: {num_points} points, duration: {time_range}\")\n",
    "    \n",
    "    # Save to parquet file\n",
    "    output_path = \"/home/crimsondeepdarshak/Desktop/Deep_Darshak/AIS_data_demo/processed/10_Day_US_interpolated_15min.parquet\"\n",
    "    print(f\"\\nSaving interpolated data to: {output_path}\")\n",
    "    interpolated_df.write_parquet(output_path, compression=\"snappy\")\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(\"No data to interpolate!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350aa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
